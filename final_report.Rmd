---
title: "Bayesian Forecasting of C02 Emissions"
author: "Noah Kochanski, Mallory Wang"
date: "4/13/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

Global warming is the change in the Earth's weather patterns over a extend period of time. Although Earth's climate changing has been a phenomenon that has occurred many times in the past, scientists agree that human activities over the past 100 years are accelerating the speed at which global warming is happening. Carbon dioxide (CO2) is one variable increasing the speed of global warming through the greenhouse gas.  Although CO2 is released through natural processes such as breathing and decomposition, humans have been adding C02 to the atmosphere at unprecedented rates through the burning of fossil fuels. In the United States, there has been an increasing demand to understand, predict, and reduce the carbon footprint as a nation. We look to explore the use of both classical and Bayes linear regression and compare the results when forecasting CO2 emissions in the United States.

## Data Introduction

Our data set of interest comes from the World Bank and includes the following variables tracked from 1960 to present day:

* Year
* C02 Emissions
* Population
* Gross Domestic Product
* Gross Domestic Income
* Net Primary Income
* Population in Urban Agglomeration
* Energy Use
* Net Energy Import
* Electric Power Consumption

As seen in the plot below, overall, CO2 emissions have been increasing with time. The dips in the graph typically correspond to times of economic turmoil in the United States. We hope to use the variables containing information about the economic status of the country to aid in our predictions. Looking at the other variables in this data, we have variables which are highly correlated with each other. As a result, we will want to pick a subset of these variables which will aid in our forecasting model.  

```{r, echo = FALSE}
library(corrplot)
library(RColorBrewer)
library(ggpubr)

# reading dataset
us_df <- read.csv("us_df.csv")


M <- na.omit(us_df[,-1])
colnames(M) <- c("C02", "Population", "GDP", "GDP Growth", "GDI", "Income", "Urban", "Energy", "Energy Import", "Electricity")
M <-cor(M)

corrplot(M,  order = "hclust", type = "lower") 

```

## Methods

### Classical Linear Regression

The first method that we propose to use is by linear regression. Since we are attempting to forecast future CO2 emissions, we use the following model, 
$$Y_t = \beta' \begin{bmatrix} X_{t-5} \\ Y_{t-5} \end{bmatrix} + \epsilon_t$$
where $Y_t$ is the observation at time, $t$ and $X_{t-5}, Y_{t-5}$ is the data at time, $t-5$. To determine the most important variables in predicting CO2 emissions, I will perform backward elimination and only keep the 5 most important predictors.

```{r, echo = TRUE}
library(tidyverse)
library(leaps)

# lagging the data 5 years
lag5 <- us_df %>% mutate_all(lag, n = 5) 
colnames(lag5) <- paste(colnames(us_df), "_5", sep="")
lagged_data <- cbind(us_df, lag5) %>% dplyr::select(-c(3:12))

# fitting the full model
full_model <- lm(co2~. ,data = lagged_data)

# backward elimination
models <- regsubsets(co2~., data = lagged_data, nvmax = 5, method = "backward")
summary(models)
```

As seen by the output above, the most important lagged variables which I will include for the following analysis are population, GDI, NPI, population in urban areas, and electric power consumption. We now fit a model which is trained on data from 1975-2004 and tested on data from 2005-2018.  



```{r}
library(tidyverse)
library(leaps)

train <- lagged_data %>% na.omit() %>% filter(year %in% 1975:2004) %>% select("co2","pop_5", "gdi_5", "inc_5", "urban_5", "elec_5")
test <- lagged_data %>% na.omit() %>% filter(year %in% 2005:2018) %>% select("co2", "pop_5", "gdi_5", "inc_5", "urban_5", "elec_5")

model_1 <- lm(co2~., data = train)

preds <- data.frame(preds = c(predict(model_1, train[,-1]), predict(model_1, test[,-1])))

plot_data <- cbind(preds, lagged_data[,1:2])
ggplot(data = pivot_longer(plot_data, cols = c("preds", "co2")), aes(x= year, y = value, color = name)) + geom_line() + geom_vline(xintercept = 2013)

```
### Bayes Linear Regression


## 
